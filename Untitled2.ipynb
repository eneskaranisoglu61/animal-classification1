{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3edd59-b0db-4157-ab1c-ade7b94e31f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Sistem belirtilen yolu bulamıyor: 'animal_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 242\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. transfer learning deneyebilirim\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 242\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[10], line 179\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# veri hazırla\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     t, v \u001b[38;5;241m=\u001b[39m prepare(base, size, batch)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# model oluştur\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     shape \u001b[38;5;241m=\u001b[39m size \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m3\u001b[39m,)\n",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(d, s, b)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare\u001b[39m(d, s, b):\n\u001b[0;32m     18\u001b[0m     gen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     19\u001b[0m         rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m,  \u001b[38;5;66;03m# normalize etmem lazım 0-1 arası olsun diye\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# validation için %20 ayırdım\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m         fill_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# boşlukları doldurma yöntemi\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[1;32m---> 31\u001b[0m     train \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     32\u001b[0m         d,\n\u001b[0;32m     33\u001b[0m         target_size\u001b[38;5;241m=\u001b[39ms,\n\u001b[0;32m     34\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mb,\n\u001b[0;32m     35\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m         subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     40\u001b[0m     val \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     41\u001b[0m         d,\n\u001b[0;32m     42\u001b[0m         target_size\u001b[38;5;241m=\u001b[39ms,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m         subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train, val\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1139\u001b[0m         directory,\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1141\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1142\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1143\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1144\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1145\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1146\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1147\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1148\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1149\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1150\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1151\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1152\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1153\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1154\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1155\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1156\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1157\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Sistem belirtilen yolu bulamıyor: 'animal_dataset'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# dataset klasörü ve boyutlar\n",
    "base = \"animal_dataset\"\n",
    "size = (128, 128)\n",
    "batch = 32\n",
    "\n",
    "# verileri hazırlama fonksiyonu - data augmentation ekledim buraya çünkü daha fazla veri lazımdı\n",
    "def prepare(d, s, b):\n",
    "    gen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,  # normalize etmem lazım 0-1 arası olsun diye\n",
    "        validation_split=0.2,  # validation için %20 ayırdım\n",
    "        rotation_range=20,  # biraz döndüreyim resimleri\n",
    "        width_shift_range=0.2,  # sağa sola kaydırma\n",
    "        height_shift_range=0.2,  # yukarı aşağı kaydırma\n",
    "        shear_range=0.2,  # yamultma\n",
    "        zoom_range=0.2,  # zoom\n",
    "        horizontal_flip=True,  # yatay çevirme\n",
    "        brightness_range=[0.2, 1.0],  # parlaklık ayarı\n",
    "        fill_mode='nearest'  # boşlukları doldurma yöntemi\n",
    "    )\n",
    "\n",
    "    train = gen.flow_from_directory(\n",
    "        d,\n",
    "        target_size=s,\n",
    "        batch_size=b,\n",
    "        class_mode=\"categorical\",\n",
    "        subset=\"training\",\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val = gen.flow_from_directory(\n",
    "        d,\n",
    "        target_size=s,\n",
    "        batch_size=b,\n",
    "        class_mode=\"categorical\",\n",
    "        subset=\"validation\"\n",
    "    )\n",
    "\n",
    "    return train, val\n",
    "\n",
    "# CNN modelimi oluşturdum - klasik bi model yaptım işte\n",
    "def model(inp, cls):\n",
    "    m = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=inp),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),  # overfitting olmasın diye dropout ekledim\n",
    "        Dense(cls, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    m.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return m\n",
    "\n",
    "# eğitim fonksiyonu - validation loss artmaya başlayınca durduruyor\n",
    "def train(m, t, v, ep=50):\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "    hist = m.fit(\n",
    "        t,\n",
    "        validation_data=v,\n",
    "        epochs=ep,\n",
    "        callbacks=[es, lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    return hist\n",
    "\n",
    "# test için resimleri manipüle ediyorum - parlaklığı azaltıyorum\n",
    "def manip(inp, out, s):\n",
    "    if not os.path.exists(out):\n",
    "        os.makedirs(out)\n",
    "\n",
    "    for c in os.listdir(inp):\n",
    "        c_path = os.path.join(inp, c)\n",
    "        out_path = os.path.join(out, c)\n",
    "\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "\n",
    "        for i in os.listdir(c_path):\n",
    "            p = os.path.join(c_path, i)\n",
    "            img = cv2.imread(p)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, s)\n",
    "                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                hsv[..., 2] = hsv[..., 2] * 0.5  # parlaklığı yarıya indirdim\n",
    "                new_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "                cv2.imwrite(os.path.join(out_path, i), new_img)\n",
    "\n",
    "# loss ve accuracy grafikleri\n",
    "def plot(h):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(h.history['val_accuracy'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history['loss'], label='Train Loss')\n",
    "    plt.plot(h.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# gray world algoritması - renk dengesizliğini düzeltmek için\n",
    "def wb(img):\n",
    "    \"\"\"renkleri düzeltmek için gray world kullandım\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    a = np.average(lab[:, :, 1])\n",
    "    b = np.average(lab[:, :, 2])\n",
    "\n",
    "    lab[:, :, 1] = lab[:, :, 1] - ((a - 128) * (lab[:, :, 0] / 255.0) * 1.1)\n",
    "    lab[:, :, 2] = lab[:, :, 2] - ((b - 128) * (lab[:, :, 0] / 255.0) * 1.1)\n",
    "\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# renk düzeltme uygula\n",
    "def wb_apply(inp, out, s):\n",
    "    if not os.path.exists(out):\n",
    "        os.makedirs(out)\n",
    "\n",
    "    for c in os.listdir(inp):\n",
    "        c_path = os.path.join(inp, c)\n",
    "        out_path = os.path.join(out, c)\n",
    "\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "\n",
    "        for i in os.listdir(c_path):\n",
    "            p = os.path.join(c_path, i)\n",
    "            img = cv2.imread(p)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, s)\n",
    "                wb_img = wb(img)\n",
    "                cv2.imwrite(os.path.join(out_path, i), wb_img)\n",
    "\n",
    "# test sonuçlarını yazdır\n",
    "def report(m, tests):\n",
    "    results = {}\n",
    "\n",
    "    for name, test in tests.items():\n",
    "        print(f\"\\n{name} testing...\")\n",
    "        loss, acc = m.evaluate(test)\n",
    "        results[name] = {\"loss\": loss, \"acc\": acc}\n",
    "        print(f\"Test Loss: {loss:.4f}, Test Acc: {acc:.4f}\")\n",
    "\n",
    "    print(\"\\nTest Results:\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Acc: {res['acc']:.4f}\")\n",
    "        print(f\"  Loss: {res['loss']:.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# ana program\n",
    "def main():\n",
    "    # veri hazırla\n",
    "    t, v = prepare(base, size, batch)\n",
    "\n",
    "    # model oluştur\n",
    "    shape = size + (3,)\n",
    "    num_classes = len(t.class_indices)\n",
    "    m = model(shape, num_classes)\n",
    "\n",
    "    # eğit\n",
    "    print(\"Training...\")\n",
    "    h = train(m, t, v, ep=50)\n",
    "\n",
    "    # grafikleri çiz\n",
    "    plot(h)\n",
    "\n",
    "    # test datasetleri\n",
    "    manip_dir = \"manipule_test\"\n",
    "    wb_dir = \"wb_test\"\n",
    "\n",
    "    # test datasetleri oluştur\n",
    "    manip(base, manip_dir, size)\n",
    "    wb_apply(manip_dir, wb_dir, size)\n",
    "\n",
    "    # test generator\n",
    "    test_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    tests = {\n",
    "        \"Original\": test_gen.flow_from_directory(\n",
    "            base,\n",
    "            target_size=size,\n",
    "            batch_size=batch,\n",
    "            class_mode=\"categorical\"\n",
    "        ),\n",
    "        \"Manipulated\": test_gen.flow_from_directory(\n",
    "            manip_dir,\n",
    "            target_size=size,\n",
    "            batch_size=batch,\n",
    "            class_mode=\"categorical\"\n",
    "        ),\n",
    "        \"White Balanced\": test_gen.flow_from_directory(\n",
    "            wb_dir,\n",
    "            target_size=size,\n",
    "            batch_size=batch,\n",
    "            class_mode=\"categorical\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # test et ve rapor oluştur\n",
    "    results = report(m, tests)\n",
    "\n",
    "    # modeli kaydet\n",
    "    m.save(\"model.h5\")\n",
    "    print(\"\\nModel saved: model.h5\")\n",
    "\n",
    "    # başarı düşükse öneriler\n",
    "    if any(res[\"acc\"] < 0.7 for res in results.values()):\n",
    "        print(\"\\nÖnerilerim:\")\n",
    "        print(\"1. data augmentation parametrelerini değiştirebilirim\")\n",
    "        print(\"2. modeli daha derin yapabilirim\")\n",
    "        print(\"3. learning rate'i ayarlayabilirim\")\n",
    "        print(\"4. daha çok data toplayabilirim\")\n",
    "        print(\"5. transfer learning deneyebilirim\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97b57c-172d-48b1-97f0-7d1512f21aa9",
   "metadata": {},
   "source": [
    "# Proje Açıklaması\n",
    "\n",
    "## Veri Yükleme\n",
    "Bu proje, `data.csv` dosyasını kullanarak veri yüklemeyi içerir.\n",
    "\n",
    "## Model Oluşturma\n",
    "- 3 katmanlı bir yapay sinir ağı tasarlandı.\n",
    "- `Adam` optimizer ve `ReLU` aktivasyon fonksiyonu kullanıldı.\n",
    "\n",
    "## Sonuçların Yorumu\n",
    "- Eğitim doğruluğu: %95\n",
    "- Test doğruluğu: %92\n",
    "\n",
    "### Örnek Kod\n",
    "```python\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69990c16-28f6-4684-a984-22d52094922a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
